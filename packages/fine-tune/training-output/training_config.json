{
  "model": "mlx-community/functiongemma-270m-it-4bit",
  "epochs": 1,
  "batch_size": 2,
  "learning_rate": 0.0002,
  "lora_rank": 8,
  "lora_layers": 16,
  "max_tokens": 512,
  "seed": 42
}